# (PART) Анализ данных {-}
# Описательные статистики

_Итак, мы загрузили данные, посмотрели на них, почистили --- пора приступить к внимательному изучению, чего мы там насобирали. Частично мы уже сталкивались с описательными статистиками в предыдущих главах --- теперь же будем разбираться подробно._

**Описательные статистики (descriptive statistics[^1])** --- обобщенные статистики, количественно описывающие особенности имеющихся данных.

**Описательная статистика (descriptive statistics[^2])** --- области статистики, занимающаяся обработкой статистических данных, их наглядным представлением, и собственно описанием через описательные статистики[^3].

**Зачем нам описательные статиски?** Чтобы ёмко описать имеющиеся данные и составить на основе этих описаний общее представление о них, а также обнаружить особенности, которые могут повлиять на дальнейший анализ.

> Слишком много описаний, поехали к делу уже!


## Меры центральной тенденции

Насколько ёмко мы хотим описать наши даннные? Ну, попробуем для начала максимально ёмко и максимально просто --- одним числом. Например, самым часто встречающимся наблюдением. Как мы будем это наблюдение искать, зависит от [шкалы](#scales) конкретной переменной.

|**Шкала**|**Мера центральная тенденции**|
|:-------:|:----------------------------:|
|*Номинальная*|Мода|
|*Порядковая*|Медиана|
|*Интервальная*|Среднее арифметическое|
|*Абсолютная*|Среднее геометрическое и др.|


### Мода

**Мода (mode)** --- наиболее часто встречающееся значение данной переменной.

Тут все достаточно просто и интуитивно понятно. Пусть у нас есть следующий вектор наблюдений:

```{r}
x <- c(1,3,4,6,4,2,4,3,2,4,1)
```

Если мы составим таблицу частот по этому вектору, то получим следующее:
```{r}
table(x)
```

Очевидно, что $4$ всречается в векторе чаще других значений --- это и есть мода.

Также очевидно, что *моду невозможно посчитать на непрерывной шкале*.

<img class="taskimg" src="img/question.png">
<div class="task">
Почему?
</div>

К сожалению, в **R** нет встроенной функции для расчёта моды.

<img class="taskimg" src="img/code.png">
<div class="task">
Напишите функцию, которая принимает на вход вектор значений дискретной переменной, и вычисляет моду данной переменной[^4]. Если мод у данной переменной несколько, необходимо вернуть все.
</div>

Формально моду можно определить как значение переменной, при котором функция вероятности (probability mass function) принимает максимальное значение:

$$
\mathrm{mode} = \max(\mathrm{PMF}(X))
$$

### Медиана
Если мы уже гуляем на просторах порядковой шкалы, то можем посчитать медиану.

**Медиана (median)** --- это значение, которые располягается на середине сортированного[^5] вектора значений переменной. То есть, она делит все наблюдения переменной ровно пополам и 50% наблюдений оказывается по одну сторону от медианы, а 50% --- по другую. По этой причине медиана также называется *вторым [квартилем](#quartiles)* распределения.

<img class="taskimg" src="img/question.png">
<div class="task">
Почему нельзя посчитать медиану на номинальной шкале?
</div>

Формальное определение медианы зависит от количества значений в векторе: если есть нечётное количество значений --- то это ровно середина сортированного вектора, если есть чётное количество наблюдение --- то медиана определяется как (арифметическое) среднее между двумя срединными наблюдениями.

$$
\mathrm{median} = \begin{cases}
X(\frac{n+1}{2}), & \text{ if } n \text{ is odd},\\
\dfrac{X(\frac{n}{2}) + X(\frac{n}{2}+1)}{2}, & \text{ otherwise},
\end{cases}
$$
где $X$ --- вектор налюдений данной переменной, $n$ --- число наблюдений, $X(a)$ --- наблюдение с индексом $a$ в сортированном векторе $X$.

Для вектора `x`, который был создан выше, расчёт медианы выглядит так:
```{r}
median(x)
```
Изи.


### Среднее
А ежели мы уже на уровне интервальной шкалы, что не грех и среднее посчитать. Вот только какое?

#### Арифметическое
Как правило, считается среднее арифметическое (поэтому если не указано иного, мы понимает под термином «среднее» именно «арифметическое среднее»), и далее люди не заморачиваются, что в целом разумно. По сему, мы уделим основное внимание ему, а другие посмотрим лишь обзорно.

С **арифметическим средним (arithmetic mean, mean, average)** все знакомы ещё со школы, и считается оно предельно просто --- суммируем все наблюдения и полученную сумму делим на количество наблюдений.

$$
\bar x = \dfrac{\sum_{i=1}^{n}x_i}{n},
$$
где $\bar X$ --- среднее арифметическое, $x_i$ --- наблюдение в векторе $X$, $n$ --- количество наблюдений.

В **R** оно считается абсолютно элементарно:
```{r}
mean(x)
```
Кстати, оценка генерального среднего через выборочное среднее --- это один из примеров [точечной оценки]() параметра [методом моментов]().

Давайте сравним для рассмотреные статистики (используем все тот же вектор `x`):
```{r, echo=FALSE}
# mode function
mode <- function(x) {
  values <- sort(unique(x))
  freqs <- tabulate(x)
  which(freqs == max(freqs))
}
```
```{r}
mode(x) # кастомная функция, отсутствует в R
median(x)
mean(x)
```
Как мы видим, хотя все три статистики описывают цкентральную тенденцию, тем не менее они всё же дают разные результаты. Посмотрим их взаимное положение на графике:
```{r, echo=FALSE}
library(ggplot2)
theme_set(theme_bw())
set.seed(108)
symm <- sample(
  x = seq(1, 10, 0.5),
  size = 200,
  replace = TRUE,
  prob = c(
    .05,
    .05,
    .07,
    .1,
    .1,
    .15,
    .20,
    .30,
    .35,
    .5,
    .35,
    .30,
    .20,
    .15,
    .1,
    .1,
    .07,
    .05,
    .05
  )
)
asymm <- sample(
  x = seq(1, 10, 0.5),
  size = 200,
  replace = TRUE,
  prob = c(
    .1,
    .2,
    .25,
    .4,
    .5,
    .5,
    .4,
    .35,
    .3,
    .25,
    .2,
    .25,
    .2,
    .15,
    .1,
    .1,
    .07,
    .05,
    .05
  )
)
graph1 <- ggplot(NULL) +
  geom_density(aes(symm)) +
  geom_density(aes(asymm), linetype = 'dashed') +
  geom_vline(xintercept = mean(symm), color = 'darkred') +
  geom_vline(xintercept = median(symm), color = 'darkblue') +
  geom_vline(xintercept = mode(symm), color = 'darkgreen') +
  geom_vline(xintercept = mean(asymm), color = 'darkred', linetype = 'dashed') +
  geom_vline(xintercept = median(asymm), color = 'darkblue', linetype = 'dashed') +
  geom_vline(xintercept = mode(asymm), color = 'darkgreen', linetype = 'dashed') +
  labs(x = 'Value',
       y = 'Density')
graph1  
```
<center style="margin-top: -2%;">
<div style="display:inline-block; margin-right: 1%; color: #7f170e; font-size: 12px;">mean</div>
<div style="display:inline-block; margin-right: 1%; color: #000d85; font-size: 12px;">median</div>
<div style="display:inline-block; color: #2a6218; font-size: 12px;">mode</div>
</center>

Что тут можно пронаблюдать?

* Есть два распределения --- более симметричное (сплошная чёрная линия) и сильно скошенное (прерывистая чёрная линия).
* Медианы (синие линии) делят площади под графиками пополам, как и ожидалось.
* Кроме того, у симметричного распределения медиана и среднее оченю близки, а у скошенного распределения среднее смещается в сторону массивного правого хвоста.
* Мода же у скошенного распредления очень близка к пику распределения.

Что из этого можно заключить?

* Близкие значения медианы и среднего --- *один из* показателей симметричности распределения[^6]
* Медиана более устойчива к выбросам

<img class="taskimg" src="img/question.png">
<div class="task">
Почему?
</div>

* Если у нас *квазинепрерывная*[^7] шкала и мы можем посчитать моду, она будет близка к пику распределения


#### Геометрическое
> Редко встречается в научных работах, но заради общего представления пусть будет.

**Геометрическое среднее (geometric mean)** идейно похоже на арифметическое, только наблюдения не складываются, а перемножаются. Отсюда появляется ключевое ограничение на его использование --- *оно может быть рассчитано только на абсолютной шкале*. В психологии абсолютных шкал прям скажем небагато, поэтому, скорее всего, вы его никогда и не встретите в практике.

<img class="taskimg" src="img/question.png">
<div class="task">
И всё же есть в психологии одна абсолютная шкала, широко используемая, например, в когнитивных исследованиях. Какая?
</div>

Вычисляется она следующим образом:

$$
G_{X} = \sqrt[n]{\prod_{i=1}^n x_i} = \Big(\prod_{i=1}^n x_i\Big)^{\tfrac{1}{n}}
$$

Встроенной функции для вычисления геометрического среднего в **R** нет, но можно поупражняться. 😊

<img class="taskimg" src="img/code.png">
<div class="task">
Напишите функцию, которая принимает на вход вектор значений переменной и вычисляет геометрическое среднее. Функция должна возвращать одно число.
</div>

Геометрическое среднее используется при работе с экспоненциально растущими величинами (например, численность населения).


#### Гармоническое
> Суперэкзотичный покемон.

Тут даже говорить не буду ничего говорить, просто насладитесь формулой, а если хотите больше, то можно покопаться, например, [здесь](https://en.wikipedia.org/wiki/Harmonic_mean).

$$
H_X = \frac{n \prod_{i=1}^n x_i}{\sum_{i=1}^n (\tfrac{1}{x} \prod_{j=1}^n x_j)} = \frac{n}{\sum_{i=1}^n \tfrac{1}{x_i}}
$$

#### Квадратичное {#quadratic_mean}
> А вот это уже более полезная история. Мы с ним столкнёмся далее, правда под разными масками.

**Квадратичное среднее (quadratic mean, root mean square, RMS)** --- это квадратный корень из среднего квадрата наблюдений. Ничего не понятно, поэтому по порядку.

* есть наблюдение $x_i$
* значит есть и его квадрат $x_i^2$
* мы умеем считать обычно среднее арифметическое, но ведь $x_i^2$ --- это тоже наблюдение, просто в квадрате, так?
* значит можем посчитать среднее арифметическое квадратов наблюдений --- *средний квадрат*

$$
\frac{\sum_{i=1}^n x_i^2}{n}
$$

* норм, а теперь извлечём из этого дела корень --- получим то, что там надо

$$
X_{\mathrm{RMS}} = \sqrt{\frac{\sum_{i=1}^n x_i^2}{n}}
$$

<img class="taskimg" src="img/question.png">
<div class="task">
Что-то оно напоминает, да?
</div>

Per se мы его вряд ли ещё когда-то увидим, но вот когда будем идеть дело с estimation theory…

<img class="taskimg" src="img/code.png">
<div class="task">
Напишите функцию, которая вычисляет квадратичное среднее по данному вектору наблюдений. Функция должна принимать на вход числовой вектор и возвращать одно число.
</div>


#### Усеченное
> Так, ну, тут уже попроще.

**Усеченное среднее (truncated mean, trimmed mean)** --- это младшая сестра среднего арифметического с той только разницей, что вычисляется не по всем наблюдениям, а по усеченной с обеих сторон выборке. То есть, из всей выборке, которая у нас есть, мы выбрасываем сколько-то низких значений и сколько-то высоких. Сколько? Ну, от 5% до 25%. По умолчанию отбрасывается по 2.5% с обеих сторон.

Зачем? Чтобы сравнить с обычным средним. Если они близки, то можно ожидать, что распределение симметрично и/или в нём нет выбросов. Если они значительно различаются, то, скорее всего, требуется почистить данные или обратить внимание на форму распределения.


#### Межквартильное
> То же самое, что и в предыдущем пункте. Почти.

**Межквартильное среднее (interquartile mean, midmean, IQM)** --- то же, что и усеченное среднее, только считаем мы по выборке, попавшей в пределы [межквартильного размаха](#iqr).

Как посчитать? Вот так:

$$
X_{\mathrm{IQM}} = \frac{2}{n} \sum_{i=\frac{n}{4}+1}^{\frac{3n}{4}} x_i
$$

<img class="taskimg" src="img/code.png">
<div class="task">
Напишите функцию, которая вычисляет усеченное среднее и межквартильное среднее по данному вектору наблюдений. Функция должна принимать на вход вектор наблюдений и долю наблюдений, которую необходимо отсечь от выборки, и возвращать именованный вектор, содержащий две требуемые статистики.
</div>


#### Взвешенное
> Полезная вещь.

Часто бывает такая ситуация, что нас нужно посчитать среднее по каким-либо имеющимся параметрам, но одни параметры для нас важнее, чем другие. Например, мы хотим вычислить суммарный балл обучающегося за курс на основе ряда работ, выполненных в течение курса, однако мы понимаем, что тест из десяти вопросов с множественном выбором явно менее показателен, чем, например, аналитическое эссе или экзаментационная оценка. Что делать? Взвесить параметры!

Что значит взвесить? Умножить на некоторое число. На самом деле, любое. Пусть мы посчитали, что написать эссе в три абстрактных раза тяжелее, чем написать тест, а сдать экзамен в два раза тяжелее, чем написать эссе. Тогда мы можем присвоить баллу за тест вес $1$, баллу за аналитическое эссе вес $3$, а экзамену --- вес $6$. Тогда итоговая оценка за курс будет рассчитываться следующим образом:

$$
\text{final score } = 1 \cdot \text{test} + 3 \cdot \text{essay} + 6 \cdot \text{exam}
$$
Суперкласс. Однако! Весьма вероятно, что в учебном заведении принята единая система оценки для всех видов работ (ну, скажем, некая абстрактная десятибалльная система в сферическом вакууме). Получается, если и за тест, и за эссе, и за экзамен у студента по 10 баллов, то суммарный балл 100, что, кажется, больше, чем 10. Чтобы вернуться к изначальным границам баллов, нужно моделить суммарный балл на сумму весов параметров:

$$
\text{final score } = \frac{1 \cdot \text{test} + 3 \cdot \text{essay} + 6 \cdot \text{exam}}{1 + 3 + 6}
$$
Кайф! Собственно, это и есть взвешенное среднее. Коэффициенты, на которые мы умножаем значение парамернов, называются *весами параметров*. И в общем виде формула принимает следующий вид.

$$
\bar x = \frac{\sum_{i=1}^n w_i x_i}{\sum_{i=1}^n w_i} = \sum_{i=1}^n w_i' x_i,
$$
где $x_i$ --- значения конкретных параметров, $w_i$ --- веса конкретных параметров, $w_i'$ --- нормированные веса параметров.

Вторая часть формулы показывается нам, что можно облегчить себе вычислительную жизнь, если заранее нормировать веса, то есть разделить каждый коэффициент на сумму коэффициентов:

$$
w_i' = \frac{w_i}{\sum_{i=1}^n w_i}
$$
Тогда сумма коэффициентов будет равна единице. Так чаще всего и поступают, так как тогда коэффициент будет представлять долю, которую весит данный параметр в суммарной оценке. Удобно, практично, красиво.

Взвещенное среднее часто применяется именно во всякого рода ассессментах, и не только образовательных. Например, вы HR-аналитик и оцениваете персонал. Вы аналитически вычисляете веса коэффициентов (допусти, с помощью линейной регрессии), а далее на их основе высчитаете интегральный балл, по которому будете оценивать сотрудников. Это как один из индустриальных примеров.

Есть специально обученная функция, которая вычисляет взвешенное среднее:

```{r}
weighted.mean(x = c(10, 8, 8), # вектор значений параметров (например, баллы за тест, эссе и экзамен)
              w = c(0.1, 0.3, 0.6)) # веса в итоговой оценке
```


> На этом список средних не заканчивается, но нам обозначенных выше будет более чем достаточно.



## Меры разброса
Несмотря на удобство и высокую степень приятности описания всей выборки только мерой центральной тенденции, этого маловато.

<center>
<img src="img/not_enough.jpg" width="50%">
</center>

Простенький пример для наглядности. Пусть у нас есть два следующих вектора:

```{r echo=FALSE}
x1 <- c(5, 50, 12, 4, 4, 6, 24)
x2 <- c(20, 30, 6, 8, 2, 11, 1, 13, 28, 31)
```

```{r}
x1
x2
mean(x1)
mean(x2)
```

Средние по выборкам одинаковы, однако мы явно наблдаем, что вектора различны. Более того, если пристально посмотреть, то мы обнаружим, что у них разный *разброс* значений. Вообще-то помня о том, что *неопределенность и вариация* --- главные характеристики статистических данных, было бы крайне неразумно пренебречь описанием этой самой вариативности. Что ж, займемся этим вопросом.

### Минимум и максимум
Как можно описать разброс? Указать минимум и максимум!

Это, во-первых, справедливо, во-вторых, просто, что даже останавливаться на этом не будем. Вот соответствующие функции:

```{r}
min(x1); min(x2) # да, точка с запятой в R тоже работает
max(x1); max(x2) # но заклинаю вас использовать её не в ущерб удобочитаемости
```

Минимум и максимум по переменных всегда полезно смотреть при исследовании данных --- так можно обнаружить ошибки записи. Например, если вы психометрик и используете в вопросах опросника семибальную шкалу его высочества Ликерта (Лайкерта), а при исследовании собранных данных обнаруживаете минимум по какому-либо вопросу 0, а максимум 9 --- явно что-то пошло не так. Или, допустим, вы анализируете заработную плату сотрудников организации и обнаруживаете минимум по переменной «фонд оплаты труда» ниже МРОТ --- повод задуматься. Конечно, сразу выкидывать наблюдения не надо, но точно надо обратить на них внимание и изучить возможные причины появления таких значений --- может сотрудник устроен на 0.1 ставки?

<img class="taskimg" src="img/code.png">
<div class="task">
*Очевидно, что минимум --- это первый элемент отсортированного (по возрастанию) массива, а максимум --- последний. А как найти минимум (или максимум) без сортировки?*

Напишите функцию, которая принимает на вход массив (вектор) и возвращает минимальный (максимальный) элемент массива. Внутри функции нельзя использовать сортировку и встроенные в R функции.

```{r echo=FALSE}
min_custom <- function(x) {
  m <- x[1]
  for (i in 2:length(x)) {
    if (x[i] < m) {
      m <- x[i]
    }
  }
  return(m)
}
max_custom <- function(x) {
  m <- x[1]
  for (i in 2:length(x)) {
    if (x[i] > m) {
      m <- x[i]
    }
  }
  return(m)
}
```
```{r}
min_custom(x1); min_custom(x2)
max_custom(x1); max_custom(x2)
```
**P.S.** Функции для поиска минимума и максимума будут практически идентичны, поэтому если вы напишите одну из них, тут же поймете, как её модифицировать, чтобы получить вторую. <br>
**P.P.S.** Да, это задание на алгоритмы, но это *единственное* задание на алгоритмы в этой книге. Вот [подсказка](). 🙄
</div>

### Размах
А если у нас есть минимум и максимум --- значит можно посчитать разницу между ими. И получить такую статистику как **размах (range)**. Добрые люди написали одноименную функцию, правда считает она не сам размах, а выводит минимум и максимум по массиву:

```{r}
range(x1)
range(x2)
```
Но это не беда, потому что другие добрые люди написали более серьезные функции, чтобы облегчить нам статистическую жизнь. С ними познакомимся далее.


### Дисперсия

Ну, хорошо, `range()` нам указал, что действительно разброс в наших векторах различный, несмотря на то, что средние в точности равны. Что нам еще надо?

Вот другой пример. Есть два таких вектора.

```{r echo=FALSE}
x3 <- c(1, 1, 2, 5, 5, 6, 8, 8, 10, 10)
x4 <- c(1, 3, 4, 4, 5, 6, 7, 7, 9, 10)
```
```{r}
x3
x4
mean(x3); mean(x4)
range(x3); range(x4)
```
Вроде и средние одинаковы, и размах одинаковый. Но вектора явно различаются. Можно даже посмотреть на картинку:
```{r}
par(mfrow=c(2,1)) # размещаем два графика друг по другом
hist(x3, breaks = 10)
hist(x4, breaks = 10)
par(mfrow=c(1,1)) # откатываем настройки обратно
```

Всё это безобразие приводит нас к мысли о том, что нам недостаточно описания «общей», «внешней» вариативности, нам надо ещё постараться как-то ухватить вариативность «внутри» ряда наблюдений. И желательно тоже в какой-нибудь одной чиселке.

<center>
<img src="img/challenge_accepted.png" width="50%">
</center>

Будем действовать аккуратно и пошагово. Что у нас есть сейчас? Мы умеем считать средне, которое отражает центральную тенденцию. Ок, давайте *зацепимся* за него и --- раз это «центр» --- будем считать вариативность относительного него. Каждое наблюдение в ту или иную сторону *отклоняется* от среднего. Ок, мы в состоянии посчитать **отклонение (deviation)** каждого наблюдения:

$$
d = \bar x - x_i
$$
Топчик! А что, если… посмотреть, как в среднем все наблюдения отклоняются от среднего значения? Отличная же идея! Считаем среднее отклонение!

$$
\frac{\sum_{i=1}^n(\bar x - x_i)}{n},
$$
$n$ --- количество наблюдений в выборке.

План хорош --- но не без изъяна… Так как отклонения у нас происходят в обе стороны от среднего --- в положительную и отрицательную --- то и в сумме они дадут нам что-то около нуля. Соответственно, и среднее отклонение у нас будет где-то около нуля. Известно, что есть два путя, как победить минус --- *взять модуль или возвести в квадрат*. Преимущество второго в том, что *сильные отклонения будут оказывать более сильное влияние на окончательное значение статистики*, в то время как для первого малые и большие отклонения равноценны. Посему, мы избирем путь Мандалора, то есть возведения в квадрат.

<center>
<img src="img/the_way.jpg">
</center>

Итак, возводим отклонения в квадрат и --- о, боги --- мы получили формулу **дисперсии, или вариации (dispersion, variance)**!

$$
\sigma^2 = \frac{\sum_{i=1}^n (\bar x - x_i)^2}{n}
$$
Так, а что мы в итоге получили? Формулу дисперсии. Какой?

Если со средними всё было легко и непринужденно, то с дисперсией нам придётся ещё поскрипеть мозгами над тем, что такое…

#### Степени свободы
[Википедия](https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)) предлагает нам следующее определение: *«количество наблюдений в финальном вычислении статистики, которые могут свободно варьироваться»*. Лаконично, красиво, непонятно.

> В собственных заплывах на просторы статистики я нашёл два подхода к тому, как можно приблизиться к пониманию концепта степеней свободы, коими здесь с вами поделюсь. Возможно, они не столько математически точны, как хотелось бы, но позволяют уловить идею. И, в прицнипе, этого достаточно, по крайней мере, до определенного момента вашего статистического бытования.

Прежде всего, необходимо вспомнить, что мы рассчитываем наши статистики на *выборке*, а не на всей генеральной совокупности. Этот факт и требует внесения коррективов в формулу.

##### Подход номер раз {-}
Обратим внимание, что для расчёта дисперсии мы первоначально *рассчитали выборочное среднее*, и далее, основываясь на рассчитанном значении, рассчитываем собственно выборочную дисперсию. То есть, чтобы рассчитать требуемую статистику, мы заранее рассчитали *ещё одну* как бы *зафиксировав* нашу выборку, чтобы нам было от чего считать отклонения. И нам надо учесть этот факт в формуле дисперсии --- вычесть из числа наблюдений единицу (ту самую «одну статистику», которую мы рассчитали). Таким образом, число степеней свободы будет $n-1$.

> Аналогичная идея будет при вычислении степеней свободы в дисперсионном анализе, например.


##### Подход номер два {-}
Это рассуждение ближе к математическому. Мы помним, что наш вектор наблюдений --- это значения некоторой случайной величины, которые в общем-то могут быть и совсем другими при последующих измерениях. А если представить, что мы знаем только среднее по выборке? Солько измерений нам надо произвести, чтобы восстановить весь ряд наших наблюдений? Если знаем среднее, значит знаем и сумму по выборке. Чтобы восстановить все наблюдения нам надо провести $n-1$ измерение, ведь если мы знаем сумму $n-1$ значений, то последнее мы высчитаем следующим образом: $x_n = \bar x - \sum_{i=1}^{n-1} x_i$. Получается, что если мы знаем среднее, то можем восстановить все $n$ наблюдений по $n-1$. Это и есть потерянная степень свободы.

> Если таки концепт степеней свободы даётся пока что сложно --- не беда. Самая главная общая идея в том, что когда мы рассчитываем выборочные статистики, нам необходимо сделать некоторые дополнительные манипуляции, чтобы избежать [*смещения оценок*](). Поэтому вводится понятие степеней свободы, которые позволяют эти манипуляции осуществить.

---

Итак, возвращаемся к дисперсии и разбираемся, что к чему. Формула, которую мы получили, справедлива для генеральной совокупности. В числителе дроби находится **сумма квадратов отклонений (сумму квадратов, sum of squares, SS)**. В знаменателе находится количество наблюдений. На выборке такая формула будет давать смещённую оценку дисперсии, поэтому она также называется *смещённая дисперсия*.

**Дисперсия генеральной совокупности (смещённая дисперсия)**
$$
\sigma^2 = \frac{\sum_{i=1}^n (\bar x - x_i)^2}{n}
$$

Для того, чтобы скорректировать оценку дисперсии, необходимо разделить сумму квадратов не на количество наблюдений, а на количество **степенйе свободы**, которое как мы выяснили равно $n-1$. Выборочная дисперсия имеет собственное обозначение $s^2$.

**Выборочная дисперсия (несмещённая дисперсия, исправленная дисперсия)**
$$
s^2 = \frac{\sum_{i=1}^n (\bar x - x_i)^2}{n-1}
$$

Функция, которая занимается вычислением дисперсии, называется `var()`, так как «вариация» (variance) --- это полный синоним дисперсии.

```{r}
var(x3); var(x4) # вычисляется несмещённая дисперсия
```
И --- voila! --- дисперсии у наших векторов действительно различны.

> — А скажи мені, автор, заради чого ми так довго топталися на цій дисперсії? <br>
— Заради майбутнього…

> Вообще концепт дисперсии --- ключевой во всем статистическом анализе, поэтому дисперсия будет встречаться нам так или иначе в каждой теме.


<img class="taskimg" src="img/code.png">
<div class="task">
*Функция для расчёта дисперсии у нас есть, а вот для суммы квадратов --- нет.* 😞

Напишите функцию, которая вычисляет сумму квадратов отклонений от среднего значения по данному вектору. Функция принимает числовой вектор и возвращает одно число.

```{r echo=FALSE}
SS <- function(x) {
  sum((mean(x) - x)^2)
}
```
```{r}
SS(x4)
```
</div>

### Стандартное отклонение


### Стандартная ошибка
### Квантили
#### Квартили
#### Процентили

## Асимметрия

## Эксцесс

## Описательные статистики в R




[^1]: Count noun, plural in this case
[^2]: Mass (uncountable) noun
[^3]: Обычно противоставляется статистическому выводу (inferential statistics), потому что не делает никаких заключений на основе данных, а просто говорит, что вот жанные такие, какие они есть.
[^4]: Обратите внимание на функцию `tabulate()`.
[^5]: Здесь важно помнить о нюансах терминов «упорядоченный» и «сортированный». *Упорядоченный* ряд наблюдений --- это ряд чисел, на котором задан определенный порядок (например, по ID испытуемого --- 1, 2, 3, 4, …), а *сортированный ряд наблюдений* --- это ряд, упорядоченный по возрастанию или убыванию.
[^6]: И очень косвенно --- нормальности распределения. Точнее будет сказать так: если распределение симметрично, то можно предположить, оно нормальное, однако это требует дополнительной проверки! Здесь надо помнить про [особенности импликации](#implication): *нормальное распределение всегда симметрично, однако не любое симметричное распределение нормально*.
[^7]: *Квазинепрерывная шкала* --- это порядковая шкала, относительно которой мы сделали допущение, что она непрерывная. Например, такое допущение делается в психометрике относительно шкалы Ликерта (Лайкерта), когда мы предполагаем, что интервал между двумя соседними значениями мы тоже описали, несмотря на то, что респондент должен выбираться между этими соседними значениями.

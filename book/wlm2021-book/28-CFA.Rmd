# Конфирматорный факторный анализ {#cfa}

## Экспресс-введение в структурное моделирование

<center>
<img src="img/cfa_meme1.png">
</center>

Вспомним, кто мы… Мы же с вами исследователи из области социальных и/или гуманитарных наук. А чем мы богаты? Теоретическими моделями, на которых мы основываем наши исследования! А какая теоретическая модель хороша? Та, которая получила эмпирическое подтверждение![^1]

А как это?…

В предыдущей главе мы научились искать, факторы, скрытые за наблюдаемыми переменными --- это уже большой шаг. Однако недостаточный. И главное ограничение PCA и EFA --- это то, что мы ищем независимые факторы/главные компоненты, в то время как структура взаимосвязей между латентными переменными может быть гораздо сложнее. Кроме того, эти скрытые переменные могут предсказывать другие наблюдаемые переменные: например, уровень вовлеченности сотрудников [возможно] будет предсказывать выполнение KPI, что в свою очередь предсказывает заработную плату. То есть в данным случае мы движемся не от наблюдаемых переменных к латентным, а в обратном направлении. А ведь влияние одних латентных конструктов могут быть опосредованы другими… И в итоге получается что-то такое:

<center>
<img src="img/sem_scheme.png">
</center>

Короче, модель может быть сколь угодно сложна --- и надо её каким-то образом эмпирически проверять. Это позволяют делать **методы структурного моделирования (structural equation modelling, SEM)**.

Что это за методы? Это группа методов, которые проверять модели (гипотезы), описывающие наши данные. Проверка состоит из двух больших шагов:

* задание теоретической модели генерации данных;
* проверка того, насколько предложенная модель хорошо подходит под наши данные.

Но, если вдуматься, то так работают все статистические методы --- даже в линейной регрессии мы сначала задаём линейную модель, а потом проверяем, насколько хорошо она описывает взаимосвязи, представленные в данных. В чем же особенность SEM?

Во-первых, в модель включаются *латентные переменные* --- мы получаем возможность их моделировать и использовать для предсказаний. Этого не может делать, например, хорошо знакомая нам линейная регрессия, так как она работает только с наблюдаемыми переменными.

Во-вторых, в модель могут быть включены *косвенные связи* --- связи между латентными переменными. То есть мы можем моделировать связи между переменными, которые мы даже не можем измерить! Ну, круто же!

Кроме того, модели удобно визуализируются с помощью диаграмм, аналогично рисунку выше.

### Сколько нужно данных? {#how_much_data}

Есть мнение, что «структурное моделирование требует большого количества данных». Не очень понятно, что считать большим количеством, однако эвристика следующая: *на один оцениваемый параметр нужно не менее 10 наблюдений*. Выглядит как что-то приемлемое.

[^1]: Это, конечно, не единственный критерий, но сейчас для нас --- аналитиков --- самый важный.



## Модель конфирматорного факторного анализа

Окей, мы брифли взглянули на то, что такое структурное моделирование. Если мы возьмем от него только часть, то получим **конфирматорный факторый анализ (confirmatory factor analysis)**. Осталось понять, какую часть надо взять.

Наша задача --- проверить факторный структуру данных, которую мы взяли из теории или нашли с помощью эксплораторного факторного анализа. То есть, в общем виде что-то такое:

<center>
<img src="img/cfa_scheme.png">
</center>

Выглядит уже не так страшно и запустанно.

Как это всё работает внутри? Сложно. Но, на самом деле, за всем стоит привычная нам множественная линейная регрессия и уже знакомый нам метод максимального правдоподобия, ведь мы всё ещё в рамках линейных моделей.

Чуть выше мы обсуждали, [сколько нужно данных](#how_much_data), и сказали, что «10 наблюдений на один параметр». Однако тактично умолчали, что есть такое параметр. Так вот *параметры* --- это, проще говоря, стрелочки на схеме выше. Это либо *факторный нагрузки*, так же как и в EFA, или *коэффициенты косвенных связей* между латентными переменными.

Конфирматорный факторный анализ в некотором смысле дополняет эксплораторный. Так, он позволяет уточнить и дополнить результаты последнего, а именно ответить на вопросы:

* пересекаются ли факторы? --- действительно ли каждый переменная обусловлена влиянием одного фактора?
* достоверны ли статистически факторные нагрузки?
* как коррелируют сами факторы и как это влияет на факторные нагрузки?
* отличается ли дисперсия фактора от нуля? --- ведь если нет, тогда этот фактор не информативен, то есть не дифференцирует респондентов

Итак, модель конфирматорного факторного анализа мы осознали. Пора писать код!



## CFA в R

### Данные

Сегодня работаем с данными по адаптации психометрической методики, направленной на измерении толерантности к неопределенности. Загрузим их, а также подключим необходимые библиотеки:

```{r}
library(tidyverse) # наш любимый
library(lavaan) # для структурного моделирования
library(semPlot) # для визуализаций 
```

```{r}
tolunc <- read_csv2('https://raw.githubusercontent.com/angelgardt/hseuxlab-wlm2021/master/data/tolerance_uncertainty.csv')
```

```{r}
str(tolunc)
```

```{r}
summary(tolunc)
```

Это одношкальная методика, поэтому все вопросы направлены на измерение одной латентной переменной --- толерантности к неопределенности. Получается очень простая модель, которую необходимо проверить.



### Синтаксис пакета `lavaan`

Однако первоначально нам надо освоиться с пакетом `lavaan` (**la**ten **va**rible **an**alysis). Это самый популярный пакет для структурного моделирования, однако у него несколько специфический синтаксис.

В теоретической модели могут присутствовать различные типы связей:

* **измерения** --- связи от наблюдаемых переменных к латентным (наблюдаемые → латентные)
* **регрессии** --- связи от латентных переменны к наблюдаемым (латентные → наблюдаемые)
* и **корреляции** --- связи между наблюдаемыми и латентными переменными (наблюдаемые → наблюдаемые, латентные → латентные)

Для того, чтобы записать такую структуру модели был придуман специальный «язык», а вернее, обозначения:

|Измерения|Регрессии|Корреляции|
|:-:|:-:|:-:|
|`=~`|`~`|`~~`|

Для CFA нам необходимы только *измерения*, так как мы хотим проверить структуру измеритеьной факторной модели.

Модель в `lavaan` --- это одна строка, которая передается в функцию. Далее функции сами парсят строку так, как им надо.

Наша модель будет записываться так:

```{r}
mdl1 <- "F1 =~ tu1 + tu2 + tu3 + tu4 + tu5 + tu6 + tu7 + tu8 + tu9 + tu10 + tu11 + tu12 + tu13 + tu14 + tu15 + tu16 + tu17 + tu18 + tu19 + tu20 + tu21 + tu22"
```

Теперь можно перейти к подбору модели.



### Подбор модели

Для конфирматорного факторного анализа в пакета `lavaan` предусмотрена функция `cfa()`, которая хочет на вход модель и данные. Попробуем:

```{r, warning=TRUE}
model1 <- cfa(mdl1, data = tolunc)
```

Модель сошлась, никаких ошибок и предупреждение нам не выдали. Хорошо.

Воспользуемся хорошо знакомой нам функцией `summary()`, чтобы посмотреть на результаты:

```{r}
summary(model1)
```

Привет, стена текста. Что тут нам надо увидеть?

Во-первых, первая строка нам говорит о том, что модель сошлась и всё хорошо. Потребовалось для этого 31 итерация.

Далее на говорят, что был использован метод максимального правдопободия (ML), в нашей модели 44 параметра и она построена на 405 наблюдениях.

Во-вторых, нам рапортуются результаты теста $\chi^2$, который тестирует гипотезу о соответствии данных теоретической модели. Как обычно, представлена сама статистика (1401.716), число степеней свободы (209) и p-value (< .001). *Нулевая гипотеза данного теста: данные согласуются с теоретической моделью.* Соответственно, если мы получаем p-значение, меньшее конвенционального 0.05, то мы вынуждены отклонить нулевую гипотезу. То есть в данном случае результаты теста говорят о том, что данные не теоретическая модель не подстверждается данными. Однако делать выводы рано. На самом деле, использовать $\chi^2$ бесполезно, так как при большом количестве данных p-value будет всегда меньше 0.05, поэтому в статьях его часто даже не указывают, а качество модели оценивают по другим метрикам, к которым мы обратимся позднее.

Далее идёт таблица факторных нагрузок. Она очень похожа на регрессионную таблицу --- и это неспроста. Это и есть те самые множественные регрессии, на которых строится математическая модель конфирматорного факторного анализа.

Здесь необходимо отметить один критичный момент: *очередность задания переменных в модели играет роль*. Процедура подбоора модели устроена так, что все переменные нормируются относительно первой, поэтому её коэффициент (нагрузка) равен единице. Собственно, по этой причине здесь возможны факторные нагрузки, большие единицы (что не встречается с EFA). Критичен этот момент ещё и с той точки зрения, что первой переменной в модели необходимо указывать ту, которая положительно связана с фактором, чтобы, номируясь относительно неё, другие переменные не меняли своего направления связи.

В общем случае далее будет идти таблица, описывающая связи между латентными переменными. Так как у нас один фактор в модели, то этой таблицы нет. Статистический вывод делается по стандартному алгоритму.

Последняя таблица --- это дисперсии остатков и факторов. Здесь необходимо обратить внимание имено на лисперсию факторов и проверить, отличается ли она статистически от нуля. В нашем случае всё ок --- дисперсия фактора значима, значит и сам фактор значим. Если же дисперсия статистически равна нулю, то существование данного фактора не нашло эмпирического подтверждения.


Можно выгрузить эти таблицы под отдельности:

```{r}
sfit <- standardizedsolution(model1)
```
```{r}
# факторные нагрузки
sfit[sfit$op == "=~", ]
```
```{r error=TRUE}
# корреляции
# в нашем случае ничего не выводится, так как в модель не включены корреляции
sfit[sfit$op == "~~" & sfit$lhs != sfit$rhs, ]
```
```{r}
# остатки
sfit[sfit$op == "~~" & sfit$lhs == sfit$rhs, ]
```



### Оценка качества модели

Окей, с моделью разобрались, но хочется всё же понять, насколько она хороша. Метрик оценки качества разработано огромное количество --- и все их `lavaan` считает автоматически. Наиболее популярны четыре: $\text{CFI}$, $\text{TLI}$, $\text{SRMR}$, $\text{RMSEA}$.

Все их можно вытащить достаточно легко:

```{r}
fitmeasures(model1, c("chisq", "gfi", "agfi","cfi", "tli", "srmr", "rmsea"))
```

Как уже говорилось выше, ориентироваться на $\chi^2$ бессмысленно. Для остальных метрик приняты следующие пороговые значения:

|Метрика|Значение|
|:--|:-:|
|**GFI** (goodness of fit) (аналог $R^2$)|$> 0.95$|
|**AGFI** (adjusted goodnes of fit)|$> 0.90$|
|**CFI** (comparative fit index)|$> 0.95$|
|**TLI** (Tucker Lewis index)|$> 0.95$|
|**RMSEA** (Root Mean Square Error of Approximation)|$< 0.05$|
|**SRMR** (Standardized Root Mean Square Residual)|$< 0.05$|

В нашем случае все метрики качества за пределами конвенциональных значений, что говорит о низком качестве построенной модели.

Также можно посмотреть на корреляцию остатков модели:

```{r}
resid(model1, type = 'cor')
```

Значения, большие 0.1, говорят о том, что данная связь недостаточно учтена в модели.



### Визуализация результатов

Визуализировать модель можно с помощью красивой диаграммы. Для этого есть функция `semPath()`, которая всё за нас сделает:

```{r cfa_model}
semPaths(model1, 'std')
```

На ней сразу отображены и факторный нагрузки, и связи между набладаемыми переменными. Пунктирная стрелка указывает на тот параметр-измерение, относительно которого были нормированы все остальные.


### Модификация модели

Пакет `lavaan` настолько хорош, что под капотом строит все модели, которые возможны на предложенных ему данных. И можно вывести так называемые индексы модификации с помощью одноименной функции:

```{r}
modificationindices(model1)
```

Индекс модификации показывает, насколько улучшится модель при включении данной связи в её структуру. Данная функцию была разработана для проведения быстрого разведочного анализа и формулирования гипотез для последующих исследований. Но несмотря на благие намерения, велик соблазн уйти на темную сторону исследовательской практики и вводить в модель дополнительные связи, находя им ad hoc объяснения. Не надо так!



### Сравнение моделей

Исключительно в учебных целях и ради демонстрации процедуры сравнения моделей мы позволим себе шалость и включим в модель связь `tu1	~~	tu2`, у которой наибольший индекс модицикации:

```{r}
mdl2 <- "F1 =~ tu1 + tu2 + tu3 + tu4 + tu5 + tu6 + tu7 + tu8 + tu9 + tu10 + tu11 + tu12 + tu13 + tu14 + tu15 + tu16 + tu17 + tu18 + tu19 + tu20 + tu21 + tu22
tu1 ~~ tu2"
```

```{r}
model2 <- cfa(mdl2, data = tolunc)
summary(model2)
```

Сравнение двух моделей выполняется с помощью привычной нам функции `anova()`:

```{r}
anova(model1, model2)
```

Наблюдаем, что модели статистически значимо различаются. По значениями знакомых нам информационных критериев AIC и BIC можно сделать вывод, что вторая модель лучше описывает данные.

[["anova.html", "19 Дисперсионный анализ 19.1 Параметризация индикаторов и параметризация эффектов 19.2 Однофакторный дисперсионный анализ 19.3 Многофакторный дисперсионный анализ 19.4 Дисперсионный анализ с повторными измерениями", " 19 Дисперсионный анализ Мы знаем, что в регрессионную модель можно включать как количественные (непрерывные), так и категориальные (дискретные) предикторы. Более того, мы знаем, как при включении категориальных предикторов изменяется модель и что значат предикторы. Теперь рассмотрим случай, когда в модели останутся только категориальные предикторы. 19.1 Параметризация индикаторов и параметризация эффектов На модель только с категориальными предикторами можно смотреть двумя разными способами. С первым мы уже частично знакомы. Если мы из моделей, рассмотренных в предыдущей главе исключим количественные предикторы, то получим модель такого вида: \\[ y_i = b_0 + b_1 I_{\\mathrm{Group_2}} \\] Здесь у нас один категориальный предиктор с двумя уровнями — переменная-индикатор \\(I_{\\mathrm{Group_2}}\\) задаёт принадлежность наблюдения ко второй группе. Если же у нашего категориального предиктора будет более двух уровней, то модель примет следующий вид: \\[ y_i = b_0 + b_1 I_{\\mathrm{Group_2}} + b_2 I_{\\mathrm{Group_3}} \\] Как это помыслить визуально? Вот так: КАРТИНКА Собственно, как мы обсуждали в предыдущей главе, в интерсепт модели \\(b_0\\) уходит baseline для группы 1, а коэффициенты при переменных \\(I_{\\mathrm{Group_i}}\\) показывают, насколько изменяется baseline в других группах по сравнению с группой 1. Кодировку групп с помощью переменных-индикаторов можно представить в такой табличке: ТАБЛИЦА Такая кодировка позволяет переписать уравнение модели в более простом виде — теперь и вовсе как обычная множественная регрессия: \\[ y_i = b_0 + b_1 x_1 + b_2 x_2 \\] Этот способ подбора коэффициентов модели называется параметризация индикаторов (dummy coding, treatment parametrization, reference cell model). В R модель подбирается автоматически в параметризации индикаторов. Подгрузим данные. Мы с ними уже знакомы — это всё тот же эксперимент об иконках share. library(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ── ## ✓ ggplot2 3.3.2 ✓ purrr 0.3.4 ## ✓ tibble 3.0.4 ✓ dplyr 1.0.2 ## ✓ tidyr 1.1.2 ✓ stringr 1.4.0 ## ✓ readr 1.4.0 ✓ forcats 0.5.0 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() theme_set(theme_bw()) share &lt;- read_csv(&quot;https://raw.githubusercontent.com/angelgardt/mk_ggplot2/master/sharexp_data.csv&quot;) ## ## ── Column specification ──────────────────────────────────────────────────────── ## cols( ## .default = col_double(), ## trialtype = col_character(), ## platform = col_character() ## ) ## ℹ Use `spec()` for the full column specifications. Напомним себе переменные: trialtype — тип пробы (tray/dots/both) setsize — количество стимулов в пробе (8/12/16) time1 — время первого клика time2 — время второго клика id — индентификатор испытуемого platform — платформа смартфона (Android/iOS) Возьмем для примера в качестве категориальной переменной setize — в ней три уровня 8, 12 и 16 (хотя в реальном анализе лучше, конечно, рассматривать её как непрерывную). share %&gt;% mutate(setsize = as_factor(setsize)) -&gt; share Подберём модель в параметризации индикаторов (сравниваем время реакции time1): model_tr &lt;- lm(time1 ~ setsize, share) model_tr ## ## Call: ## lm(formula = time1 ~ setsize, data = share) ## ## Coefficients: ## (Intercept) setsize12 setsize16 ## 1.3704 0.2220 0.4641 Смысл полученных чисел таков: в условии с восемью стимулами в пробе среднее время реакции 1.37 с, а в условиях с 12 и 16 стимулами оно больше на 0.22 и 0.46 с соответственно. Другой способ смотреть на влияние фактора на нашу целевую переменную — это эффект фактора. Он складывается из отклонений средних значений в группах по фактору от общего среднего. КАРТИНКА В кодировке отклонений уровней дискретного фактора от общего среднего коэффициенты модели начинают отражать вклад каждого уровня факторв в его общий эфффект. Такая кодировка называется параметризацией эффектов (effects coding, sum-to-zero parameterization). Таблица кодировки групп переменной будет несколько отличаться: ТАБЛИЦА Математическая запись модель не меняется, однако интерпретация коэффициентов будет иная: \\[ y_i = b_0 + b_1 x_1 + b_2 x_2 \\] Подберём модель в параметризации эффектов: model_ef &lt;- lm(time1 ~ setsize, share, contrasts = list(setsize = contr.sum)) model_ef ## ## Call: ## lm(formula = time1 ~ setsize, data = share, contrasts = list(setsize = contr.sum)) ## ## Coefficients: ## (Intercept) setsize1 setsize2 ## 1.599066 -0.228689 -0.006699 Коэффициент теперь другие: \\(b_0\\) — среднее время реакции во всех группах по переменной setsize, а \\(b_1\\) и \\(b_2\\) — это отличия среднего времени реакции в группах 8 и 12 от среднего времени реакции. Возникает вопрос: куда делась группа 16? Если внимательно посмотреть на таблицу кодирования групп, то можно обнаружить, что одна из групп кодируется через -1 — то есть, чтобы узнать среднее время реакции в группе 16 надо провести следующее вычисление: \\(b_0 - b_1 - b_2\\) — в нашем случае получится 1.83. Надо сказать, что хотя уравнения моделей получаются разные — коэффициенты при предикторах различаются — это одна и та же модель. Чтобы это доказать, посмотрим на предсказания на новых данных: new_share &lt;- tibble(setsize = factor(c(8, 12, 16))) predict(model_tr, new_share) ## 1 2 3 ## 1.370377 1.592367 1.834454 predict(model_ef, new_share) ## 1 2 3 ## 1.370377 1.592367 1.834454 19.2 Однофакторный дисперсионный анализ Здесь всё просто. У нас один фактор — категориальная переменная с несколькими уровнями — и мы хотим узнать, оказывает ли влияние данный фактор на нашу зависимую переменную. Вернее, конечно, правильнее было бы сказать, связан ли данный фактор в нашей зависимой переменной. Но так как дисперсионный анализ часто используется для анализа экспериментальных данных, мы будем говорить о влиянии, помня всё детали, на которые мы уже неоднократно обращали внимание. 19.2.1 Зачем вообще дисперсионный анализ? Вопрос, на самом деле, не праздный. «Регрессия только с категориальными предикторами» — звучит несколько странно. Да и потом, ведь по факту мы сравниванием несколько групп между собой — чё бы t-тест не использовать? Проще и понятнее. Так-то оно, конечно, так, но мы помним о проблеме множественных сравнений. Дисперсионный анализ на от неё спасает, так как позволяет тестирования влияние фактора целиком, не сравнивая группы друг с другом. 19.2.2 Структура изменчивости Мы говорили, что основные характеристики статистических данных — неопределённость и вариативность. И эта вариативность (изменчивость) имеет определенную структуру. Прежде всего, есть общая изменчивость, которая складывается [сумм квадратов] отклонений от общего среднего: \\[ SS_\\mathrm t = \\sum_{i=1}^n (\\bar y - y_i)^2, \\quad \\mathrm{df}_\\mathrm t = n-1 \\] КАРТИНКА Часть от неё составляет факторная (межгрупповая) изменчивость — это отклонения внутригрупповых средних от общего среднего: \\[ SS_\\mathrm x = \\sum_{j=1}^p (\\bar y - \\bar y_j)^2, \\quad \\mathrm{df}_\\mathrm x = p-1 \\] КАРТИНКА Оставшуюся часть составляет случайная (внутригрупповая) изменчивость: \\[ SS_\\mathrm e = \\sum_{i=1}^n \\sum_{j=1}^p (\\bar y_j - y_{ij})^2, \\quad \\mathrm{df}_\\mathrm e = n-p \\] Таким образом, \\[ SS_\\mathrm t = SS_\\mathrm x + SS_\\mathrm e \\] 19.2.3 Тестирование значимости фактора От сумм квадратов можно перейти к дисперсиям — вернее, к средним квадратам: \\[ MS_\\mathrm t = \\frac{SS_\\mathrm t}{\\mathrm{df}_\\mathrm t}, \\quad MS_\\mathrm x = \\frac{SS_\\mathrm x}{\\mathrm{df}_\\mathrm x}, \\quad MS_\\mathrm e = \\frac{SS_\\mathrm e}{\\mathrm{df}_\\mathrm e} \\] \\(MS_\\mathrm x\\) и \\(MS_\\mathrm e\\) помогают тестировать значимлсть фактора. Если зависимости между фактором и целевой переменной нет, то \\(MS_\\mathrm x \\approx MS_\\mathrm e\\). Гипотеза формулируется так: \\[ H_0: \\mu_1 = \\mu_2 = \\dots = \\mu_p \\\\ H_1: \\exists i,j: m_i \\neq m_j \\\\ F_{\\mathrm{df}_\\mathrm x, \\mathrm{df}_\\mathrm e} = \\frac{MS_\\mathrm x}{MS_\\mathrm e} \\overset{H_0}{\\thicksim} F (\\mathrm{df}_\\mathrm x, \\mathrm{df}_\\mathrm e) \\] Результаты дисперсионного анализа обыно представляются в виде таблицы: ТАБЛИЦА 19.2.4 Дисперсионный анализ в R Функция для дисперсионного анализа есть много, но мы воспользуется функцией Anova() из пакета car, потому что она хороша. library(car) ## Loading required package: carData ## ## Attaching package: &#39;car&#39; ## The following object is masked from &#39;package:dplyr&#39;: ## ## recode ## The following object is masked from &#39;package:purrr&#39;: ## ## some Anova(model_tr) ## Anova Table (Type II tests) ## ## Response: time1 ## Sum Sq Df F value Pr(&gt;F) ## setsize 581.9 2 410.17 &lt; 2.2e-16 *** ## Residuals 11488.3 16197 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Anova(model_ef) ## Anova Table (Type II tests) ## ## Response: time1 ## Sum Sq Df F value Pr(&gt;F) ## setsize 581.9 2 410.17 &lt; 2.2e-16 *** ## Residuals 11488.3 16197 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Вот вам пожалуйста — табличка дисперсионного анализа. В случае однофакторного дисперсионного анализа нам всё равно, какой метод параметризации использовать — результаты будут одинаковые. Теперь обратим внимание на результат. Да, фактор количества стимулов значим, но что это значит технически? Что есть хотя бы две группы, которые значимо различаются между собой. Какие — нам не известно. Чтобы это узнать, необхожимо провести… 19.2.5 Post hoc тесты 19.3 Многофакторный дисперсионный анализ 19.4 Дисперсионный анализ с повторными измерениями "]]

[["regularization.html", "23 Регуляризация регрессии", " 23 Регуляризация регрессии Мы говорили о том, что частой проблемой при подборе модели линейной регрессии является мультиколлинеарность предикторов. Напомним, чем это чревато. В случае абсолютно линейной связи коэффициент модели просто не вычислится — в аутпуте будет NA. Как правило, это намёк на то, чтобы проверить данные — возможно, у вас есть одна и та же переменная, записанная по-разному (например, рост в метрах и сантиметрах). В случае высоких (но меньших единицы) корреляций проблема подбора коэффициентов решается с помощью методов численной оптимизации, однако это может приводить к смещённым оценкам коэффициентов модели, а также большим ошибкам в оценках коэффициентов. Поэтому с мультиколлинеарностью надо бороться. Мы уже обсуждали метод служебной регрессии. Теперь обсудим ещё один способ. С случае мультиколлинеарности оценки ряда коэффициентов могут быть завышены. Значит нужно их «штрафовать»! Вернее, не сами коэффициенты, а сумму квадратов ошибок модели: \\[ RSS + \\text{штраф} \\rightarrow \\underset{\\hat \\beta}{\\min} \\] "]]

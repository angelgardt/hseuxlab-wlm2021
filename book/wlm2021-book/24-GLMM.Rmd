# Смешанные линейные модели {#glmm}

## Ограничения изученных ранее линейных моделей

При построении обычных линейных моделей мы предполагаем, что наши наблюдения независимы. Однако зачастую это требование не выполняется в полной мере, и наши данные имеют некоторую группировку (clustered data), которую, возможно, мы даже не планировали.

Примеры возможных группировок:

* измерения в разные периоды времени (разные партии химических реактивов, разные настройки аппаратуры)
* измерения в разных участках пространства (мониторы компьютеров могут различаться)
* повторные измерения (испытуемые / респонденты различаются между собой)
* измерения на разных группах испытуемых / респондентов (школьники разных классов в одной параллели могут различаться)

Возникают *внутригрупповые корреляции* --- наблюдения из одной группы более похожи друг на друга, чем наблюдениях из разных групп.

Подобную структуру данных некорректно игнорировать --- увеличивается вероятность ошибиться с выводами. Интуитивное решение: включить группирующие факторы в модель в качестве предикторов --- технически так, безусловно, сделать можно, однако такой подход, во-первых, значительно усложные модель (чрезмерно увеличивается количество параметров), а во-вторых, ограничивает широту обобщения результатов (интерпретаировать параметры модели можно только для конкретных испытуемых / респондентов / учебных классов).

Чтобы решить возникающие трудности, необходимо ввести в модель **случайные факторы**.



## Случайные vs фиксированные факторы

До сих пор мы работали только с **фиксированными факторами** --- моделировали среднее значение для каждго уровня фактора. Если групп возникает много, то и моделируемых средных значений также много. Кроме того, когда мы задавали фиксированные факторы, мы считали, что сравниваемые группы фиксированные, и нас интересуют сравнения именно между ними.

Однако когда группировка возникает не как результат дизайна исследования, а как некоторый побочный результат (то есть, мы не планировали изучать фактор, по которому разделилась наша выборка), нам не важны конкретные значения интерсептов в каждой из групп. Мы можем представить данный фактор как случайную величину (величину «поправки»), и оценить дисперсию между уровнями группирующего фактора. Это и есть **случайные факторы**.

|Свойства|Фиксированные факторы|Случайные факторы|
|:-------|:--------------------|:----------------|
|Уровни фактора|Фиксированные, заранее определенные, потенциально воспроизводимые|Случайная выборка из всех возможных уровней|
|Используются для тестирования гипотез|О средних значениях ЗП на разных уровнях фактора$H_0: \mu_1 = \mu_2 = \dots = \mu$|О дисперсии ЗП между уровнями фактора $H_0: \sigma^2_r = 0$|
|Выводы можно экстраполировать|Только на уровни анализа|На все возможные уровни|

<font size = 2> [Источник](https://www.coursera.org/learn/smeshannye-lineynye-modeli) </font>

На один и тот же фактор можно смотреть и как на случайный, и как на фиксированный в зависимости от задач исследователя. Так как мы хотим моделировать дисперсию, то у случайного фактора должно быть минимум пять градаций.



## Почему обычные методы плохо работают?

Подгружаем [данные](https://raw.githubusercontent.com/angelgardt/mk_ggplot2/master/sharexp_data.csv):

```{r}
library(tidyverse)
theme_set(theme_bw())
```
```{r}
share <- read_csv('https://raw.githubusercontent.com/angelgardt/mk_ggplot2/master/sharexp_data.csv')
```
```{r}
str(share)
share %>% mutate(trialtype = as_factor(trialtype),
                 time1 = 1000 * time1,
                 id = as_factor(id),
                 platform = as_factor(platform)) -> share
```

Это данные, которые мы уже обсчитали вдоль и поперёк, но ещё не совсем. Поведенческий эксперимента, в котором пользователи Android и iOS искали иконки «share» обеих платформ среди универсальных иконок. Короче, зрительный поиск.


Нас будут интересовать следующие переменные:

* `trialtype` --- тип пробы (`tray`/`dots`/`both`)
* `setsize` --- количество стимулов в пробе (`8`/`12`/`16`)
* `time1` --- время первого клика
* `id` --- индентификатор испытуемого
* `platform` --- платформа смартфона (`Android`/`iOS`)

В нашем случае `id` --- это наш группирующий фактор (повторные измерения).

Перед построением моделей сабсетнем данные, чтобы получать осмысленные результаты:
```{r}
share %>% filter(trialtype != 'both') -> share
```

### Плохое решение: игнорирование группирующего фактора

Построим модель без учета повторных измерений.
```{r}
fit1 <- glm(time1 ~ setsize, family = Gamma, data = share)
summary(fit1)
```

Визуализируем модель:

```{r glmm1}
share %>% ggplot(aes(setsize, time1)) +
  geom_point() +
  geom_smooth(method = 'lm')
```

Что плохо?

1) Завышен объем выборки (10800 наблюдений вместо 36 испытуемых) → Увеличивается вероятность ошибки I рода.
2) Нарушено условие независимости наблюдений


### Плохое решение: включение группирующего фактора как фиксированного

Построим такую модель:
```{r}
fit2 <- glm(time1 ~ setsize + id, family = Gamma, data = share)
summary(fit2)
```

Визуализируем:
```{r glmm2}
share %>% ggplot(aes(setsize, time1, color = id)) +
  geom_point() +
  geom_smooth(method = 'lm')
```

Что плохо?

1) 37 предикторов (ок, у нас, конечно, 10800 наблюдений, это нас может спасти, но в общем случае нам может не хватить мощности на тестирование такого количества предикторов)
2) Нужно минимум 20 наблюдений на каждый параметр (опять же, нам повезло, но в общем случае может и не хватить)
3) Широта обобщения --- сравниваем только представленных испытуемых, теряется универсальность модели.



## Виды GLMM и их математическая формулировка

Мы строим прямые --- модели же линейные. А прямая задается двумя параметрами --- интерсептом и углом наклона (slope). Эти параметры мы оцениваем в качестве фиксированных факторов. Но так как других у нас нет, то эти же параметры оцениваются и как случайные факторы. То есть, случайные факторы как бы дополняют фиксированные.


### Математическая формулировка модели со случайным интерсептом

$$ y_{ij} = \beta_0 + \beta_1 x_{ij} + \eta_i + \varepsilon_{ij}$$
$$ \eta_i \thicksim \mathcal{N}(0, \, \sigma^2_\eta) $$
$$ \varepsilon_{ij} \thicksim \mathcal{N}(0, \, \sigma^2) $$
$i$ --- наблюдение (респондент), $j$ --- уровни (значения) предиктора


### Математическая формулировка модели со случайными интерсептом и углом наклона
$$ y_{ij} = \beta_0 + \beta_1 x_{ij} + \eta_{0i} + \eta_{1ij} x_{ij}+ \varepsilon_{ij}$$
$$ \eta_{0i} \thicksim \mathcal{N}(0, \, \sigma^2_{\eta_0}) $$
$$ \eta_{1ij} \thicksim \mathcal{N}(0, \, \sigma^2_{\eta_1}) $$
$$ \varepsilon_{ij} \thicksim \mathcal{N}(0, \, \sigma^2) $$
$i$ --- наблюдение (респондент), $j$ --- уровни (значения) предиктора



## Подбор моделей со смешанными эффектами

Посмотрим на график:

```{r glmm3}
share %>% ggplot(aes(setsize, time1, shape = id)) +
  stat_summary(fun = mean, geom = 'point', position = position_dodge(.1)) +
  stat_summary(fun = mean, geom = 'line', position = position_dodge(.1)) +
  scale_shape_manual(values = c(65:90, 97:107))
```

Для подбора смешанных моделей существует несколько пакетов. Мы будем использовать `lmer4`.

Модель со случайным интерсептом:
```{r}
library(lme4)
```
```{r}
mix1 <- lmer(time1 ~ setsize + (1|id), data = share)
```
```{r}
summary(mix1)
```

Модель со случайными интерсептом и углом наклона:
```{r}
mix2 <- lmer(time1 ~ setsize + (1 + setsize|id), data = share)
```
```{r}
summary(mix2)
```

Итак, видно что аутпут значительно отличается от тех, что мы видели ранее. К этому мы еще вернемся. Чтобы более содержательно поговорить о том, что получилось, необходимо понять, как подбираются параметры в смешанных моделях.



## Методы подбора параметров в смешанных моделях

Параметры в смешанных моделях могут подбираться двумя методами. Первый из них --- **метод максимального правдоподобия (maximum likelihood, ML)**.


**Правдоподобие (likelihood)** --- способ измерить соответствие имеющихся данных тому, что можно получить при определенных значениях параметров модели. Оно представляет собой произведение вероятностей получения каждой из точек данных:

$$
L(\theta | \mathrm{data}) = \prod_{i=1}^n f(\mathrm{data}|\theta),
$$

где $f(\mathrm{data}|\theta)$ --- функция распределения с параметрами $\theta$.

Параметры модели должны максимизировать значения [логарифма] правдоподобия, т.е.

$$
L(\theta | \mathrm{data}) \rightarrow \max
$$

Однако для упрощения вычислений используют логарифмы правдоподобий (loglikelihood) и максимизируют их.

$$
\ln L(\theta | \mathrm{data}) \rightarrow \max
$$

Аналитически такие задачи решаются редко, чаще используются методы численной оптимизации.

Однако когда мы пытаемся оценить дисперсию методом максимального правдоподобия, оценки получаются смещенными. Это происходит потому, что сразу приходится оценивать и $\beta$ и дисперсии.

Этого можно избежать, применяя метод **ограниченного максимального правдоподобия (restricted maximum likelihood, REML)**. Данный метод позволяет с помощью математических преобразования занулить $\beta$ и получить несмещенные оценки дисперсий.

REML-оценки $\beta$ стремятся к ML-оценкам при увеличении объема выборки.


### REML или ML?

* Если нужны точные оценки фиксированных эффектов --- ML.
* Если нужны точные оценки случайных эффектов --- REML.
* Если нужно работать с правдоподобиями --- следите, чтобы в моделях, подобранных REML была одинаковая фиксированная часть.
* Для обобщенных негауссовских смешанных линейных моделей REML не определен --- там используется ML.



## Диагностика модели

### Индуцированные корреляции

Появление в модели случайного фактора позволяет учесть взаимосвязь наблюдений для каждого из респондентов --- «индуцированные» корреляции.

Посмотрим внимательно на случайную часть модели.

* Случайные эффекты, распределенные нормально со средним 0 и некоторой дисперсией

$$ \eta \thicksim \mathcal{N}(0, \, \sigma^2_\eta) $$

* Остатки модели, *независимые* распределенные нормально со средним 0 и некоторой дисперсией

$$ \varepsilon \underset{\mathrm{i.i.d.}}{\thicksim} \mathcal{N}(0, \, \sigma^2) $$

Путем математических преобразований матриц ковариаций можно получить, что **корреляция между наблюдениями одного субъекта** равна следующему выражению. Эта характеристика называется **коэффициент внутриклассовой корреляции (intra-class correlation, ICC)**.

$$ \mathrm{ICC} = \frac{\sigma^2_\eta}{(\sigma^2_\eta + \sigma^2)}$$

Таким образом, ICC --- это способ измерить, насколько коррелируют друг с другом наблюдения из одной и той же группы, заданной случайным фактором. Значения ICC интерпретируются аналогично коэффициенту корреляции.

Если ICC низкий, то наблюдения очень разные внутри каждой из групп. Значит, чтобы надежно оценить эффект этого случайного фактора, нужно брать больше наблюдений в группе.

Если ICC высокий, то наблюдения очень похожи внутри каждой из групп, заданных случайным фактором. Значит, можно брать меньше наблюдений в группе.

Это можно использовать при определении объема выборки (при анализе пилотных данных).

Посчитает ICC для модели со случайным интерсептом. Для этого воспользуемся одноименной функцией из пакета `sjstats`:

```{r}
# install.packages('performance')
performance::icc(mix1)
```


### Анализ остатков модели

Нужно провести анализ остатков модели, чтобы понять, можно ли с ней работать дальше. Одна из потенциальных проблем --- время реакции разных субъектов может меняться непараллельно. Возможно, модель придется переформулировать.

Подготовим данные для анализа остатков.
```{r}
res <- tibble(share,
              fitted = fitted(mix1),
              resid = resid(mix1, type = 'pearson'),
              sresid = resid(mix1, type = 'pearson', scaled = TRUE))
str(res)
```

Визуализируем стандартизованные остатки.

```{r glmm6}
gg_res <- ggplot(res, aes(y = sresid)) +
  geom_hline(yintercept = 0)
gg_res + geom_point(aes(x = fitted))
```
На графике ответливо визуализируется воронкообразный паттерн, что свидетельструет о гетерогенности дисперсий --- не выполнено условие гомоскедастичности. Кроме того, наблюдаются большие остатки. Во-первых, помним о том, что мы не чистили данные, а во-вторых, все равно для многих наблюдений модель плохо работает.

Визуализируем зависимость остатков от факторов модели.

```{r glmm4}
gg_res + geom_boxplot(aes(x = factor(share$setsize)))
```

Вновь наблюдается гетерогенность дисперсий и большие остатки.

```{r glmm5}
gg_res + geom_boxplot(aes(x = factor(share$id)))
```

Опять видим гетерогенность дисперсий и большие остатки.



## Предсказания с помощью моделей. Сравнение точности предсказаний смешанных и обычных моделей

Сделаем новый датафрей для предсказаний:
```{r}
new_share <- share %>% select(setsize, id)
```

Запишем предсказания моделей:
```{r}
new_share$pred_mix <- predict(mix1, new_share, type = 'response')
new_share$pred_lm <- predict(fit1, new_share, type = 'response')
```

Посчитаем ошибки моделей:
```{r}
err_mix <- sum((new_share$pred_mix - share$time1)^2)
err_lm <- sum((new_share$pred_lm - share$time1)^2)
err_mix
err_lm
```

Ошибка, конечно же, огромная, поскольку мы включили в модель только один предиктор. К тому же, мы выяснили, что разброс данных велик. Однако главное, что нам хотелось понять с помощью этих манипуляций --- ошибка модели со случайным эффектом меньше, чем аналогичной модели, но с включением респондента в качестве фиксированного предиктора. 
Вот пруф:
```{r}
err_mix < err_lm
```

Такие дела.



## Тестирование гипотез

С помощью смешанных моделей можно тестировать статистические гипотезы. Но есть проблема: тесты, применяемые для GLM (t- и z-тесты Вальда, LRT) дают *приблизительные* оценки. Для отбора моделей используют информационные критерии (AIC).

«Золотой стандарт» точности результатов тестов можно получить с помощью параметрического бутстрепа (см. Faraway, 2017).


### t-тест Вальда

$$
H_0: \beta_k = 0 \\
H_1: \beta_k \neq 0 \\
\\
t = \frac{b_k - \beta_k}{SE_{b_k}} = \frac{b_k}{SE_{b_k}} \thicksim \mathrm t(n-p)
$$

Так как эти тесты дают лишь приблизительные оценки, их значения даже не представлены в `summary()` модели.

```{r}
summary(mix1)
```

Их можно вернуть --- и так часто делают. **Однако при интерпретации получаемых результатов всегда нужно помнить, что это только приблизительные оценки!**

Потребуется пакет `lmerTest`:
```{r}
library(lmerTest)
mix1.1 <- lmer(time1 ~ setsize + (1|id), data = share)
summary(mix1.1)
```


### Тест отношения правдоподобий (likelihood ratio test, LRT)

$$ \mathrm{LRT} = 2 \ln \left( \frac{L_\mathrm{M_1}}{L_\mathrm{M_2}} \right) = 2 (\ln L_\mathrm{M_1} - L_\mathrm{M_2}), $$
где $\mathrm{M}_1,\, \mathrm{M}_2$ --- вложенные модели ($\mathrm{M}_1$ --- более полная, $\mathrm{M}_2$ --- уменьшенная),
$L_\mathrm{M_1}, \, L_\mathrm{M_2}$ --- правдоподобия.

Распределенеи разницы логарифмов правдоподобий аппроксиммируется распределением $\chi^2$ с числом степеней свободы $\mathrm{df} = \mathrm{df}_\mathrm{M_2} - \mathrm{df}_\mathrm{M_1}$.


### LRT для случайных эффектов

Требуются модели **с одинаковой фиксированной частью**, подобранные **REML**. Уровни значимости будут завышены. **Обычно тесты не делают**, а набор случайных эффектов определяется структурой данных.

```{r}
mix1 <- lmer(time1 ~ setsize + (1|id), data = share, REML = TRUE)
mix2 <- lmer(time1 ~ setsize + (1 + setsize|id), data = share, REML = TRUE)

anova(mix1, mix2, refit = FALSE)
```

Получается, что время у разных респондентов по-разному зависит от сетсайза.


### LRT для фиксированных эффектов

Требуются модели **с одинаковой случайной частью**, подобранные **ML**. Уровни значимости будут занижены.

```{r}
mix3.null <- lmer(time1 ~ 1 + (1|id), data = share, REML = FALSE)
mix3 <- lmer(time1 ~ setsize + (1|id), data = share, REML = FALSE)

anova(mix3.null, mix3)
```

Время реакции зависит от сетсайза.


## Сравнение моделей с помощью AIC

Можно сравнивать вложенные или невложенные модели, подобранные ML, с одинаковой случайной частью.

```{r}
AIC(mix3.null, mix3)
```

AIC падает, что говорит о том, что модель становится лучше.


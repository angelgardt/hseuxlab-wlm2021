# Пуассоновская регрессия {#poisson}

В жизни и практике мы часто сталкиваемся с так называемыми *счётными величинами*. Например, число комнат в квартире, количество детей в семье, число книг на полке, число людей, прошедших через турникет и т.д. Глобально --- любые количества. Также как счётные величины можно рассмотреть шкалу Лайкерта или оценки по десятибалльной шкале --- по сути, это количество набранных баллов.

Какими свойствами обладают такие величины?

* Они могут принимать *только целочисленные значения* ($x \in \mathbb Z$)
* Также возможны *нулевые значения* ($0 \leq x \leq +\infty$)
* Разброс значений *зависит от среднего значения* ($\mathrm{var}(X) \propto \mathbb{E}(X)$)

До сих пор мы обсуждали модели, применимые только к мерным, или непрерывным, величинам[^1]. Иногда свойства данных позволяют использовать такие методы для моделирования счётных величин, однако так бывает далеко не всегда.

[^1]: Не считая, конечно, биномиальную регрессию.

В этой главе мы обсудим самый простой подход к моделированию счетных величин, а также одну его модификацию, которая может быть полезна.

Модели для счётных данных базируются н **распределении Пуассона**.


## Распределение Пуассона

Распределение Пуассона опредляется следующим образом:

$$
Y \thicksim \mathrm{Poisson}(\mu) \\
f(y) = \frac{\mu^y e - \mu}{y!}
$$

$\mu$ --- единственный параметр данного распределения[^2]. Он задаёт и математическое ожидание, и дисперсию, т. е.

[^2]: В отличие от нормального распределения, которое задается двумя параметрами $X \thicksim \mathcal{N}(\mu, \sigma^2)$

$$
\mathbb{E}(Y) = \mu \\
\mathrm{var}(Y) = \mu \\
y \in \mathbb{N}_0
$$

Как $\mathbb{N}_0$ здесь обозначено множество натуральных чисел с нулем.

В зависимости от того, какие значения принимает этот параметр, распределение принимает достаточно сильно различающиеся формы. При низких значения ($\mu = 1, \mu = 2$) в распределение присутствует сильная левосторонняя асимметрия, при высоких ($\mu = 10$) --- распределение становится симметричным и очень похожим на нормальное распределение.

<center>
<img src="img/poisson.png">
</center>

Необходимо отметить, что пуассоновское распределение предполагает, что дисперсия связана с математическим ожидание через  *функцию идентичности*[^3], то есть с увеличением математического ожидания дисперсия возрастает ровно так же, как и само математичекое ожидание. Это факт нам будет важен далее.

[^3]: С этой функцией вы хорошо знакомы --- это самая простая линейная функция вида $y = x$.



## Почему обычные регрессионные модели плохо работают на счётных данных

Ещё раз отметил два ключевых свойства пуассоновского распределения:

* множество значений целевой переменной --- натуральные числа с нулём: $y \in \mathbb{N}_0$
* дисперсия целевой переменной зависит от матиматического ожидания: $\mathrm{var}(Y) \propto \mathbb E(Y)$

Первое свойство нам говорит о том, что количество не может быть отрицательным, и это логично. Обчная линейнная регрессия не имеет подобных ограничений, поэтому в предсказаниях *будут появляться отрицательные значения*. Что с ними делать не очень понятно.

Второе свойство говорит нам о том, что изначально *не будет выполнено допущение гомоскедастичности остатков*, так как чем выше математичекое ожидание, тем выше дисперсия. В итоге мы будем наблюдать воронкообразный паттер в распределении остатков:

<center>
<img src="img/poisson_residuals.png">
</center>

Таким образом, оценки коэффициентов модели будут неточны, ошибки завышены, а следовательно, и результатам тестирования статистической значимости параметров модели доверять нельзя.

Что делать?

Можно пойти простым путём --- **логарифмировать целевую переменную** и построить модель для получившейся величины.

Но более корректным вариантом будет построить модель, основанную на распределении, подходящем для счётных данных. В частности, пуассоновском распределении.


## Данные

Сегодня мы будем работать с данными эксперимента, в котором изучалась роль интерфейсных влияний на формирование положительного пользовательского опыта. Данные [тут](https://raw.githubusercontent.com/angelgardt/hseuxlab-wlm2021/master/book/wlm2021-book/data/trust_data.csv).

Грузим:

```{r}
library(tidyverse)
```

```{r}
satis <- read_csv('https://raw.githubusercontent.com/angelgardt/hseuxlab-wlm2021/master/book/wlm2021-book/data/trust_data.csv')
```

Смотрим:

```{r}
str(satis)
```

Исследовании проводилось на материале рекомендательной системы, варьировались два компонента интерфейса:

* `feedback` --- тип фидбека:
  - `good` --- «хороший», предъявляемый в нужном месте и нужное время
  - `bad` --- «плохой», предъявляемый не там, где надо, и не тогда, когда надо
* `explanation` --- объяснение работы рекомендательного алгоритма, которое могло быть представлено (`yes`) или скрыто от пользователя (`no`).

Именно эти две переменные нас будут интересовать в качестве предикторов.

В качестве зависимой переменной мы возьмем грейд по шкале SUS (System Usability Scale). Сейчас это переменная `sus_mark`. Однако сейчас она текстовая, нам необходимо её перекодировать в счётную числовую. Можно это сделать через `ifelse()`. Создадим новую переменную `sus_grade`:

```{r}
satis$sus_grade <- recode(satis$sus_mark,
                          'A' = 5, 'B' = 4, 'C' = 3, 'D' = 2, 'E' = 1, 'F' = 0)
```

Вот теперь хорошо. Можно строить модель!



## GLM с пуассоновским распределением целевой переменной

Мы с вами всё ещё во фреймфорке GLM, поэтому формулировка модели в общем виде будет выглядеть аналогично биномиальной регрессии:

$$
\mathrm{sus\_grade}_i \thicksim \mathrm{Poisson}(\mu_i) \\
\mathbb{E} (\mathrm{sus\_grade}_i) = \mu_i, \quad \mathrm{var}(\mathrm{sus\_grade}_i) = \mu_i \\
\ln(\mu_i) = \eta_i
$$

Если в случае биномальной регрессии *функция связи*, использовавшаяся для линеаризации зависимости между целевой переменной и предикторами была $\mathrm{logit}()$ и требовала много предварительных преобразований, то в данном случае всё проще: функция связи --- это [натуральный] логарифм $\ln()$. Применяя её к нашей переменной, мы получаем величину $\eta_i$, которую можем моделировать линейной моделью.

Возьмем в качестве предикторов тип фидбека (`feedback`), наличие/отсутствие объяснения работы алгоритма (`explanation`) и их взаимодействие (`feedback:explanation`). Получим такую модель:

$$
\eta_i = b_0 + b_1 I_{\mathrm{feedback}_\mathrm{good}} + b_2 I_{\mathrm{explanation}_\mathrm{yes}} + b_3 I_{\mathrm{feedback}_\mathrm{good}} \cdot I_{\mathrm{explanation}_\mathrm{yes}}
$$

### Подбор модели в R


Зафитим модель в R:

```{r}
model1 <- glm(sus_grade ~ feedback * explanation, data = satis,
              family = poisson)
```

Как видите, мы используем ту же функцию `glm()`, что и в случае биномиальной регрессии. Меняется только семество моделей --- теперь у нас `poisson`.

Посмотрим `summary()` по модели:

```{r}
summary(model1)
```

Можно заметить, что аутпут выглядит совершенно аналогично аутпуту биномиальной регрессии:

* Отсутствует $R^2$
* Отсутствует $F$-статистика, а значит и p-value для неё
* Значимость коэффициентов при предикторах тестируется при помощи z-тестов Вальда

В данному случае у нас получился один значимый предиктор --- `feedbackgood`. Это значит, что уровень удовлетворённость пользователей, которые взаиможействовали с интерфейсом, в котором реализован хороший фидбек, отличается от уровня удовлетворенности пользователей, которые взаимодействовали с интерфейсов и плохим фидбеком. То есть данные интерфейсы формируют различный пользовательский опыт. Но насколько различный?


## Интерпретация коэффициентов модели

Вспомним, что линейная модель описывает переменную $\eta_i$, поэтому уравнение модели мы можем записать следующим образом:

$$
\eta_i = 0.89 + 0.31 I_{\mathrm{feedback}_\mathrm{good}}
$$

Незначимые предикторы мы в модель включать не будем.

Так как $\eta_i = \ln(\mu_i)$, то

* угловой коэффициент *при непрерывном предикторе* показывает, *на сколько единиц изменится значение логарифма зависимой переменной при увеличении значения предиктора на единицу*
* угловой коэффициент *при категориальном предикторе* показывает, *на сколько единиц отличается среднее значение логарифма зависимой переменной для данной категории наблюдений по сравнению в базовым уровнем* (его, как обычно, содержит intercept модели)

Само же значение зависимой переменной изменяется в $e^{b_j}$ раз.

Таким образом, в нашем случае мы можем сказать, что `sus_grade` для интерфейса с хорошим фидбеков в среднем в $e^{0.31} = 1.36$ раза выше, чем для интерфейса с плохим фидбеком. Звучит очень логично.

Однако перед интерпретацией предикторов обычно мы проверяли, значима ли модель в целом. Давайте это сделаем, а то как-то не по порядку пошли…


## Анализ девиансы

В случае пуассоновской модели анализ девиансы не отличается от случая биномиальной регрессии. Нам так же нужна нулевая модель, в которой будет только интерсепт:

```{r}
model_null <- glm(sus_grade ~ 1, data = satis, family = poisson)
```

И функция `anova()`, которая будет сравнивать нашу модель с нулевой. Используем `test = 'Chi'`:

```{r}
anova(model1, model_null, test = 'Chi')
```

Наблюдаем, что модель статистически значима. Это очень хорошо.


## Проверка на сверхдисперсию (overdispersion)

Но не совсем… Пока что мы не можем однозначно доверять данным результатам, так как не проверили одного важного прежположения, которое положили в основу пуассоновской регрессии. А именно --- допущение о том, что $\mathbb E(X) = \mathrm{var}(X)$. В общем случае ведь связь дисперсии и математического ожидания не обязательно описывается функцией идентичности.

Если дисперсия не равна среднему значению, то мы не можем доверять результатам подбора модели.

Чтобы провести проверку на сверхдисперсию, можно воспользоваться [функцией, которую предложил Ben Bolker](http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#testing-for-overdispersioncomputing-overdispersion-factor):

```{r}
overdisp_fun <- function(model) {
  rdf <- df.residual(model)
  if (inherits(model, 'negbin'))
    rdf <- rdf - 1
  rp <- residuals(model, type = 'pearson')
  Pearson.chisq <- sum(rp ^ 2)
  prat <- Pearson.chisq / rdf
  pval <-
    pchisq(Pearson.chisq, df = rdf, lower.tail = FALSE)
  c(
      chisq = Pearson.chisq,
      ratio = prat,
      rdf = rdf,
      p = pval
    )
}
```

Проверим модель на сверхдисперсию:

```{r}
overdisp_fun(model1)
```

Данная функция рассчитывает статистику $\chi^2$ (`chisq`), по которой определяет отношение дисперсии к среднему значению (`ratio`), и рассчитывает p-value. Так как пуассоновская модель исходит из предположения равенства дисперсии и математического ожидания, то значение `ratio` должно быть близко к единице. В данном случае мы это и имеем: дисперсия в 0.94 раза превышает математическое ожидание, то есть на самом деле, даже немного ниже математического ожидания. P-value говорит нам о том, что сверхдисперсии нет --- мы можем доверять результатам нашей модели.

А если бы сверхдисперсия всё же была? Чем это плохо?

Для распределения Пуассона у нас есть следующие уравнения:

$$
\mathrm{var}(y_i) = \mu_i \\
\mathrm{var}(\mathbb E(y_i)) = \frac{\mu_i}{n} \\
\mathrm{SE}_{\mathbb E(y_i)} = \sqrt{\mathrm{var}(\mathbb E(y_i))}
$$

Если обнаружена сверхдисперсия, то данные не подчиняются распределению Пуассона, и дисперсия в $\varphi$ раз больше среднего ($\varphi > 1$). Тогда,

$$
\mathrm{var}(y_i) = \varphi \mu_i \\
\mathrm{var}(\mathbb E(y_i)) = \frac{\varphi \mu_i}{n} \\
\mathrm{SE}_{\mathbb E(y_i)} = \sqrt{\varphi \mathrm{var}(\mathbb E(y_i))}
$$

А так как пуассоновская модель не знает, что там есть какое-то $\varphi$, то:

* доверительная зона предсказаний модели будет заужена из-за того, что оценки стандартных ошибок занижены;
* тесты Вальда для коэффициентов модели дадут неправильные результаты из-за того, что оценки стандартных ошибок занижены. Уровень значимости будет занижен;
* тесты, основанные на сравнении правдоподобий, дадут смещенные результаты, т.к. соотношение девианс уже не будет подчиняться $\chi^2$-распределению.

Каковы могут быть причины сверхдисперсии? Перечислим основные:

* в данных есть выбросы
* в модель не включен важный предиктор или взаимодействие предикторов
* нарушена независимость выборок (есть внутригрупповые корреляции)
* выбрана неподходящая функция связи
* выбрана неподходящая функция распределения для целевой переменной

А что же делать? Пусти есть разные. Мы рассмотрим наболее простой.



## Квазипуассоновские модели

Первое, что надо запомнить --- **«квази-пуассоновсного» распределения не бывает!** Эти модели также основываются на распределении Пуассона, но учитывают тот самый коэффициент $\varphi$, описывающий сверхдисперсию --- поправка на избыточность дисперсии.

Записать квазипуассоновскую модель можно следующим образом:

$$
y_i \thicksim \mathrm{QuasiPoisson}(\mu_i) \\
\mathbb{E}(y_i) = \mu_i \\
\mathrm{var}(y_i) = \varphi \mu_i \\
\ln(\mu_i) = \eta_i
$$

$\varphi$ оценивается по имеющимся данным. Само же уравнение модели совершенно не изменится:

$$
\eta_i = b_0 + b_1 I_{\mathrm{feedback}_\mathrm{good}} + b_2 I_{\mathrm{explanation}_\mathrm{yes}} + b_3 I_{\mathrm{feedback}_\mathrm{good}} \cdot I_{\mathrm{explanation}_\mathrm{yes}}
$$


### Квазипуассоновские модели в R

Хотя мы не обнаружили избыточность дисперсии при диагностике модели, давайте построим квазипуассоновскую модель и посмотрим на её отличия от пуассоновской регрессии.

```{r}
model2 <- glm(sus_grade ~ feedback * explanation, data = satis,
              family = "quasipoisson")
```

```{r}
summary(model2)
```

Взглянем на аутпут. У нас, ожидаемо, изменились результаты тестирования статистической значимости коэффициентов, хотя сами коэффициенты остались теми же самыми. Почему?

Да, *оценки параметром модели* в квазипуассоновских и пуассоновских моделях *получаются одинаковыми*, однако

* стандартные ошибки коэффициентов домножатся на $\sqrt{\varphi}$;
* доверительные интервалы коэффициентов домножаются на $\sqrt{\varphi}$;
* логарифмы правдоподобий, используемые для тестирования статистической значимости моделей, уменьшаются в $\varphi$ раз.

А так как тестирование статистической значимости работает со стандартными ошибками, то и статистическая значимость также изменяется.


## Особенности работы с квазипуассоновскими моделями

Кроме того, если ряд других отличий. Одно из них можно обнаружить в аутпуте функции `summary()`: *в тестах параметров используются t-тесты и, соответственно, t-распределение* в отличие от других GLM, где используются z-тесты Вальда и стандарнтное нормальное распределение.

*Для анализа девиансы используются F-тесты*, а не $\chi^2$:

```{r}
model_null2 <- glm(sus_grade ~ 1, data = satis, family = "quasipoisson")
```

```{r}
anova(model2, model_null2, test = 'F')
```

А также для квазипуассоновских моделей не определена функция максимального правдоподобия, поэтому *нельзя вычислить AIC*.


> В завершении стоит отметить, что пуассоновские модели --- это история, скорее, для исследователей. В индустрии даже на счетных данных чаще всего используют обычные линейные модели, хотя это и не то чтобы суперкорректно.
